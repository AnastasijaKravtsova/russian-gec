{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/cephfs/home/kravtsova/hse/thesis/ML-You-Can-Use/ml_venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "LOG = logging.getLogger(\"probas\")\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.disable(logging.INFO)\n",
    "import json\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "\n",
    "import requests\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Add parent dir, so we can access our common code\n",
    "import os, sys, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "# from mlyoucanuse.bert_fun import (\n",
    "#     get_alternate_words, \n",
    "#     get_word_probabilities,\n",
    "#     get_word_in_sentence_probability, \n",
    "#     sum_log_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('/home/kravtsova/rubert_cased_L-12_H-768_A-12_pt/vocab.txt', do_lower_case=False)\n",
    "bert_model = BertForMaskedLM.from_pretrained('/home/kravtsova/rubert_cased_L-12_H-768_A-12_pt',\n",
    "                                             config=\"/home/kravtsova/rubert_cased_L-12_H-768_A-12_pt/bert_config.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = bert_model.to('cuda')\n",
    "bert_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_prob(\n",
    "    sentence: str, bert_model: BertForMaskedLM, bert_tokenizer: BertTokenizer, batch_size: int = 32\n",
    ") -> float:\n",
    "    device = bert_model.device\n",
    "    \n",
    "    positions = []\n",
    "    subtokens = []\n",
    "    \n",
    "    offset = 0\n",
    "    for token in sentence.split():\n",
    "        st = bert_tokenizer.encode(token, add_special_tokens=False)\n",
    "        positions.append((offset, offset + len(st)))\n",
    "        offset += len(st)\n",
    "        subtokens.extend(st)\n",
    "    \n",
    "    start_token_id = [bert_tokenizer.cls_token_id]\n",
    "    end_token_id = [bert_tokenizer.sep_token_id]\n",
    "    \n",
    "    if len(subtokens) > 510:\n",
    "        LOG.warning(\"Too many tokens, should be 510 or less, found %s\", total_tokens)\n",
    "    softmax = torch.nn.Softmax(dim=2).to(device=device)\n",
    "    \n",
    "    bert_model.eval()\n",
    "    \n",
    "    full_data = [start_token_id\n",
    "             + subtokens[:start]\n",
    "             + [bert_tokenizer.mask_token_id]*(end-start)\n",
    "             + subtokens[end:] + end_token_id\n",
    "             for start, end in positions]\n",
    "    \n",
    "    res = []\n",
    "    with torch.no_grad():\n",
    "        for batch_start in range(0, len(full_data), batch_size):\n",
    "            batch = torch.tensor(full_data[batch_start:batch_start+batch_size], device=device)\n",
    "            outputs = bert_model(batch, token_type_ids=batch * 0)\n",
    "            predictions = softmax(outputs[0]) * 100\n",
    "            predictions = predictions.log().cpu().numpy()\n",
    "            \n",
    "            for row, (start, end) in zip(predictions, positions[batch_start:batch_start+batch_size]):\n",
    "                for i in range(start, end):\n",
    "                    res.append(row[i+1][subtokens[i]])\n",
    "    \n",
    "    return sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict\n",
    "\n",
    "def get_alternate_words(\n",
    "    sentence: str,\n",
    "    word_index: int,\n",
    "    bert_model: BertForMaskedLM,\n",
    "    bert_tokenizer: BertTokenizer,\n",
    "    top: int = 10,\n",
    ") -> Tuple[Tuple[str, float]]:\n",
    "    \n",
    "    device = bert_model.device\n",
    "    whole_tokens = sentence.split()\n",
    "    bert_token_map = {\n",
    "        idx: bert_tokenizer.encode(whole_token, add_special_tokens=False)\n",
    "        for idx, whole_token in enumerate(whole_tokens)\n",
    "    }\n",
    "    bert_token_map[word_index] = bert_tokenizer.encode(\n",
    "        \"[MASK]\", add_special_tokens=False\n",
    "    )\n",
    "    total_tokens = len(list(chain.from_iterable(bert_token_map.values())))\n",
    "    LOG.debug(\"total bert tokens: %s whole tokens: %s\", total_tokens, len(whole_tokens))\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    start_token_id = bert_tokenizer.encode(\"[CLS]\", add_special_tokens=False)\n",
    "    end_token_id = bert_tokenizer.encode(\"[SEP]\", add_special_tokens=False)\n",
    "    the_tokens = list(chain.from_iterable(bert_token_map.values()))\n",
    "    LOG.debug(bert_tokenizer.convert_ids_to_tokens(the_tokens))\n",
    "    indexed_tokens = list(start_token_id) + the_tokens + list(end_token_id)\n",
    "    softmax = torch.nn.Softmax(dim=1).to(device=device)\n",
    "    with torch.no_grad():\n",
    "        # pylint: disable=not-callable,no-member\n",
    "        tokens_tensor = torch.tensor([indexed_tokens]).to(device=device)\n",
    "        segments_tensors = torch.tensor(\n",
    "            [\n",
    "                torch.zeros(  # type: ignore\n",
    "                    len(indexed_tokens), dtype=int\n",
    "                ).tolist()\n",
    "            ]\n",
    "        ).to(device=device)\n",
    "        outputs = bert_model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "        predictions = softmax(outputs[0].squeeze(0))\n",
    "    # to find the true index of the desired word; count all of the tokens and subtokens before\n",
    "    the_word_idx = (\n",
    "        len(\n",
    "            list(\n",
    "                chain.from_iterable(\n",
    "                    [vals for key, vals in bert_token_map.items() if key < word_index]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        + 1\n",
    "    )\n",
    "    probas, indices = torch.topk(  # pylint: disable=no-member\n",
    "        predictions[the_word_idx], top\n",
    "    )\n",
    "    alt_words = bert_tokenizer.convert_ids_to_tokens(indices.cpu().tolist())\n",
    "    return tuple(zip(alt_words, probas.cpu().tolist()))  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('в', 0.9766497611999512),\n",
       " ('за', 0.003301926888525486),\n",
       " ('на', 0.0021766619756817818),\n",
       " ('смотреть', 0.00120127375703305),\n",
       " ('через', 0.0004980001249350607),\n",
       " ('музыкальную', 0.0004563286202028394),\n",
       " ('посмотреть', 0.00041629490442574024),\n",
       " ('во', 0.0003552580892574042),\n",
       " ('новую', 0.00034798699198290706),\n",
       " ('работать', 0.0003149556287098676))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_alternate_words(sentence='Я иду на школу', \n",
    "                    word_index=2,\n",
    "                    bert_tokenizer=bert_tokenizer,\n",
    "                    bert_model=bert_model,\n",
    "                    top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оставить/убрать запятую (проверка вероятности рубертом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/excluded_test_ya_speller_punct.txt', 'r', encoding='utf8'\n",
    "         ) as f:\n",
    "    test = f.readlines()\n",
    "sents = [x.strip() for x in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf1b055057340e2b10708bcc6c61340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хотя природные явления ( извержения , цветения водорослей , землетрясения , и т .\n",
      "Экологи показывали страшные фотографии и дали неопределенные угрозы , которые могут происходить на АЭС до или после строительства .\n",
      "плакат А . Николаева , за который арестовали его в 2012\n",
      "Работал с 1966 до 2008\n",
      "Общая площадь : 68 кв .\n",
      "В связи с тем , что эра Сталина произошло вместе со становлении Магадана , Магадан также стал частью механизмы террора и тирании сталинской власти .\n",
      "Какие плюсы и минусы существуют ? ( Независимость , гордость своей страной , возвращение национальной культуры / нереальность обучения на этих языках , падание от большого русско говоряшего мира , современность русского языка , и . т . д . )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j,sent in tqdm(enumerate(sents)):\n",
    "    if ',' in sent:\n",
    "        spl = sent.split()\n",
    "        for i, tok in enumerate(spl):\n",
    "            orig_prob = sentence_prob(sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model)\n",
    "    #         print('Orig sent: {}'.format(sent))\n",
    "    #         print('Orig sent prob: {}'.format(orig_prob))\n",
    "            if tok == ',':\n",
    "                tmp = sent.split()\n",
    "                del tmp[i]\n",
    "                new_sent = ' '.join(tmp)\n",
    "                new_prob = sentence_prob(new_sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model)\n",
    "        #             print('New sent: {}'.format(new_sent))\n",
    "        #             print('New sent prob: {}'.format(new_prob))\n",
    "                thr = 10\n",
    "                if new_prob > (orig_prob + thr):\n",
    "                    sents[j] = sent = new_sent\n",
    "#                     print(new_sent)\n",
    "    print(sent)\n",
    "#     with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/RULEC-GEC_test_ya_speller_punct_comma-masked-no-lowercase.txt', 'a', encoding='utf8') as f:\n",
    "#         print(sent, file=f, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Маскирование однословного предлога рубертом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/RULEC-GEC_test_ya_speller_punct_comma-masked-no-lowercase.txt', 'r', encoding='utf8') as f:\n",
    "with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/excluded_test_ya_speller_punct.txt', 'r', encoding='utf8') as f:\n",
    "    test_orig = f.readlines()\n",
    "test_orig = [x.strip() for x in test_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('russian_preps.txt', 'r') as f:\n",
    "    rus_preps = f.readlines()\n",
    "rus_preps = {x.strip() for x in rus_preps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/RULEC-GEC_test_ya_speller_punct_comma-masked-no-lowercase_parsed.txt',\n",
    "#          'r') as f:\n",
    "with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/excluded_test_ya_speller_punct_parsed.txt', 'r') as f:\n",
    "    test_ya_parsed = f.read()\n",
    "test_parsed = test_ya_parsed.split('\\n\\n')\n",
    "del test_parsed[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for sent in test_parsed:\n",
    "    inds = []\n",
    "    spl = sent.split('\\n')\n",
    "    synt_info = [x.split('\\t') for x in spl]\n",
    "    i = 0\n",
    "    while i < len(synt_info):\n",
    "        tok = synt_info[i]\n",
    "        if (tok[3] == 'ADP') and (tok[7] == 'case'):\n",
    "            start = i\n",
    "            i += 1\n",
    "            while i < len(synt_info) and synt_info[i][7] == 'fixed':\n",
    "                i += 1\n",
    "            prep = ' '.join([x[1] for x in synt_info[start:i]]).lower()\n",
    "            if prep in rus_preps:\n",
    "                inds.append(start)\n",
    "        i += 1\n",
    "    indices.append(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9461574014642fea01466755410b522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig sent: Ради этого я жила в России четыре месяца и планирую вернуться туда на год .\n",
      "Orig sent prob: 25.459430158138275\n",
      "New sent: До этого я жила в России четыре месяца и планирую вернуться туда на год .\n",
      "New sent prob: 35.542846247553825\n",
      "Orig sent: Чхартишвили окончил историко-филологическое отделение Института стран Азии и Африки в МГУ .\n",
      "Orig sent prob: -12.113512516021729\n",
      "New sent: Чхартишвили окончил историко-филологическое отделение Института стран Азии и Африки при МГУ .\n",
      "New sent prob: 4.087726026773453\n",
      "Orig sent: Даже перед того , как видела эту сцену , я знала , что должно происходить .\n",
      "Orig sent prob: 30.641615748405457\n",
      "New sent: Даже после того , как видела эту сцену , я знала , что должно происходить .\n",
      "New sent prob: 54.77656734455377\n",
      "Orig sent: Во времени войны было сложно путешествовать в восточной Европе .\n",
      "Orig sent prob: 7.343004658818245\n",
      "New sent: Ко времени войны было сложно путешествовать в восточной Европе .\n",
      "New sent prob: 19.72600269317627\n",
      "Orig sent: Хотя многие бы сказали , что первый человек эмигрировал сам по воли , мало согласилось бы с тем , что второй человек тоже переехал добровольно .\n",
      "Orig sent prob: 49.64673659205437\n",
      "New sent: Хотя многие бы сказали , что первый человек эмигрировал сам против воли , мало согласилось бы с тем , что второй человек тоже переехал добровольно .\n",
      "New sent prob: 67.94745322689414\n",
      "Orig sent: В обеих фильмах , ситуация решена в музыкальном номере , где герои поют о блага разнообразного мира .\n",
      "Orig sent prob: 10.617428429424763\n",
      "New sent: В обеих фильмах , ситуация решена в музыкальном номере , где герои поют для блага разнообразного мира .\n",
      "New sent prob: 35.340113546699286\n",
      "Orig sent: Я не эксперт по этой области , но я считаю , что никто не самом деле ничего не узнает на таких курсах .\n",
      "Orig sent prob: 42.277039708569646\n",
      "New sent: Я не эксперт в этой области , но я считаю , что никто не самом деле ничего не узнает на таких курсах .\n",
      "New sent prob: 53.31543745845556\n",
      "Orig sent: Я не считаю произведения Айн Рэнд художественной литературой , а полемикой - то есть ее главная цель не была написать вымышленную фантазию , а пропагандировать капиталистические индивидуалистические идеи через реалистичной борьбы человеческого творчеста против коллектива .\n",
      "Orig sent prob: 5.653508838266134\n",
      "New sent: Я не считаю произведения Айн Рэнд художественной литературой , а полемикой - то есть ее главная цель не была написать вымышленную фантазию , а пропагандировать капиталистические индивидуалистические идеи посредством реалистичной борьбы человеческого творчеста против коллектива .\n",
      "New sent prob: 20.601670622825623\n",
      "Orig sent: В сути , они были террористами .\n",
      "Orig sent prob: 7.819805145263672\n",
      "New sent: По сути , они были террористами .\n",
      "New sent prob: 22.506919965147972\n",
      "Orig sent: И пресная , и соленая вода используется в многих разных областях .\n",
      "Orig sent prob: 23.08689507842064\n",
      "New sent: И пресная , и соленая вода используется во многих разных областях .\n",
      "New sent prob: 38.4908629655838\n",
      "Orig sent: В современном обществе в протяжении своей жизни взрослые часто проходят через несколько профессиональных студий , иногда сменяя свою профессию 3-4 раза .\n",
      "Orig sent prob: 42.159152161329985\n",
      "New sent: В современном обществе на протяжении своей жизни взрослые часто проходят через несколько профессиональных студий , иногда сменяя свою профессию 3-4 раза .\n",
      "New sent prob: 58.587057396769524\n",
      "Orig sent: Сегодня инновационные компании множат способы адаптации к новым рынкам , то есть компания должен постоянно улучшает свой продукт , а также найдёт новые рынки , например , на интернете , в других регионах , странах и так далее .\n",
      "Orig sent prob: 60.62053856253624\n",
      "New sent: Сегодня инновационные компании множат способы адаптации к новым рынкам , то есть компания должен постоянно улучшает свой продукт , а также найдёт новые рынки , например , в интернете , в других регионах , странах и так далее .\n",
      "New sent prob: 75.01581907272339\n",
      "Orig sent: Я считаю , что в России больше ударились в развлекательные программы .\n",
      "Orig sent prob: 9.11955027282238\n",
      "New sent: Я считаю , что в России больше ударились на развлекательные программы .\n",
      "New sent prob: 19.45844566822052\n",
      "Orig sent: По-моему , мне очень важно помнить , что речь идет о образовании .\n",
      "Orig sent prob: 35.17453795671463\n",
      "New sent: По-моему , мне очень важно помнить , что речь идет об образовании .\n",
      "New sent prob: 46.659876704216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# с удалением предлога\n",
    "for j,(sent,ind) in tqdm(enumerate(zip(test_orig[4504:], indices[4504:]))):\n",
    "    removed = 0\n",
    "    for i in ind:\n",
    "        i -= removed\n",
    "        sub = get_alternate_words(sentence=sent, \n",
    "                    word_index=i,\n",
    "                    bert_tokenizer=bert_tokenizer,\n",
    "                    bert_model=bert_model,\n",
    "                    top=1)[0][0]\n",
    "        probs = []\n",
    "        tokens = sent.split()\n",
    "        no_prep = ' '.join(tokens[:i] + tokens[i+1:])\n",
    "        no_prep_prob = sentence_prob(no_prep, bert_tokenizer=bert_tokenizer, bert_model=bert_model)\n",
    "        probs.append((no_prep_prob, no_prep, 1))\n",
    "        orig_prob = sentence_prob(sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model)\n",
    "        if sub.lower() in rus_preps and sub != sent.split()[i]:\n",
    "            tmp = sent.split()\n",
    "            tmp[i] = sub\n",
    "            new_sent = ' '.join(tmp)\n",
    "            new_prob = sentence_prob(new_sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model)\n",
    "            probs.append((new_prob, new_sent, 0))\n",
    "        thr = 10\n",
    "        max_prob, max_sent, new_removed = max(probs)\n",
    "        if max_prob > (orig_prob + thr):\n",
    "            print('Orig sent: {}'.format(sent))\n",
    "            print('Orig sent prob: {}'.format(orig_prob))\n",
    "            print('New sent: {}'.format(max_sent))\n",
    "            print('New sent prob: {}'.format(max_prob))\n",
    "#             sent = max_sent\n",
    "            test_orig[j] = sent = max_sent\n",
    "            removed += new_removed\n",
    "    with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/RULEC-GEC_test_ya_speller_punct_comma-masked-no-lowercase_prep-masked-deleted.txt', 'a', encoding='utf8') as f:\n",
    "        print(sent, file=f, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de88298ae5cb4732a47f42b872cab77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig sent: Потому что они постоянно находятся в меняющемся рынке , они редко застигнуты врасплох .\n",
      "Orig sent prob: 9.066727340221405\n",
      "New sent: Потому что они постоянно находятся на меняющемся рынке , они редко застигнуты врасплох .\n",
      "New sent prob: 27.873316407203674\n",
      "Orig sent: Можно спорить с идей , что Россия западная страна , но пока Россия стремится к западному стандарту жизни , следует согласиться , что стандарты , способы и термины будет похожие .\n",
      "Orig sent prob: 36.78791615366936\n",
      "New sent: Можно спорить насчет идей , что Россия западная страна , но пока Россия стремится к западному стандарту жизни , следует согласиться , что стандарты , способы и термины будет похожие .\n",
      "New sent prob: 46.82103311084211\n",
      "Orig sent: Леонтьев не только работал в Америке ; он как-то успел влюбиться на красивую американскую поэтессу Эстель Маркс .\n",
      "Orig sent prob: 2.015134032815695\n",
      "New sent: Леонтьев не только работал в Америке ; он как-то успел влюбиться в красивую американскую поэтессу Эстель Маркс .\n",
      "New sent prob: 25.189017847180367\n",
      "Orig sent: А благодаря Платону , Сократ умирал с честью .\n",
      "Orig sent prob: 5.919526547193527\n",
      "New sent: А согласно Платону , Сократ умирал с честью .\n",
      "New sent prob: 21.236687421798706\n",
      "Orig sent: Есть возможность , что представителей Гуманитарного Действия приедут в город Вашингтон летом и , лучше всего , в Портленд в ноябре ! Я сказала , что я готова переводить для них и работать экскурсоводом , если на самом дело приедут к нашей замечательный город .\n",
      "Orig sent prob: 16.43581374362111\n",
      "New sent: Есть возможность , что представителей Гуманитарного Действия приедут в город Вашингтон летом и , лучше всего , в Портленд в ноябре ! Я сказала , что я готова переводить для них и работать экскурсоводом , если на самом дело приедут в нашей замечательный город .\n",
      "New sent prob: 30.331588461995125\n",
      "Orig sent: Она рассчитана особо для специалистов этого академической сферы , а я даже не смог понять , о чем говорит текст аннотации .\n",
      "Orig sent prob: 12.81396608799696\n",
      "New sent: Она рассчитана особо на специалистов этого академической сферы , а я даже не смог понять , о чем говорит текст аннотации .\n",
      "New sent prob: 23.163510882295668\n",
      "Orig sent: Так и было , когда я вернулась от России .\n",
      "Orig sent prob: 5.23707127571106\n",
      "New sent: Так и было , когда я вернулась из России .\n",
      "New sent prob: 29.34580272436142\n",
      "Orig sent: Этос науки - это идея , что ученые должны использовать знание ради других ученых и обычных людей в обществе .\n",
      "Orig sent prob: 29.083738312125206\n",
      "New sent: Этос науки - это идея , что ученые должны использовать знание для других ученых и обычных людей в обществе .\n",
      "New sent prob: 39.818369284272194\n",
      "Orig sent: Блок защищает себя и поэму « Двенадцать » при суде\n",
      "Orig sent prob: -4.032145321369171\n",
      "New sent: Блок защищает себя и поэму « Двенадцать » в суде\n",
      "New sent prob: 10.754963055253029\n",
      "Orig sent: Большие праздники вам не нужны ; лучше думать о всех маленьких случаях , которые каждый день случаются .\n",
      "Orig sent prob: 37.511705845594406\n",
      "New sent: Большие праздники вам не нужны ; лучше думать обо всех маленьких случаях , которые каждый день случаются .\n",
      "New sent prob: 47.99016383290291\n",
      "Orig sent: Он правил с рождении в 1886 г .\n",
      "Orig sent prob: -18.934312343597412\n",
      "New sent: Он правил при рождении в 1886 г .\n",
      "New sent prob: 5.446122348308563\n",
      "Orig sent: Из-за машин , в воздух попадает вредные вещества .\n",
      "Orig sent prob: 2.246925413608551\n",
      "New sent: Помимо машин , в воздух попадает вредные вещества .\n",
      "New sent prob: 15.763025373220444\n",
      "Orig sent: В первой фотографии стоит молодая женщина , которая одета в стиле 70-х годов .\n",
      "Orig sent prob: 43.31731462478638\n",
      "New sent: На первой фотографии стоит молодая женщина , которая одета в стиле 70-х годов .\n",
      "New sent prob: 58.1629044264555\n",
      "Orig sent: В 70-ых остальные федеральные законы против пива были разъяснены - право варить пиво возвращало , и идея из зелёной революции распространена в домашнее и ремесленное пивоварение .\n",
      "Orig sent prob: -15.50301836617291\n",
      "New sent: В 70-ых остальные федеральные законы против пива были разъяснены - право варить пиво возвращало , и идея из зелёной революции распространена на домашнее и ремесленное пивоварение .\n",
      "New sent prob: -1.8501311913132668\n",
      "Orig sent: Даже перед 1991 Балтийские страны вышли из союза , можно сказать , что это действие решило судьбу СССР .\n",
      "Orig sent prob: 13.162844061851501\n",
      "New sent: Даже в 1991 Балтийские страны вышли из союза , можно сказать , что это действие решило судьбу СССР .\n",
      "New sent prob: 26.49690341949463\n",
      "Orig sent: К сожалению , человек может идти в политику , рада человечества , потом там остаться ради деньги .\n",
      "Orig sent prob: -5.051344707608223\n",
      "New sent: К сожалению , человек может идти в политику , рада человечества , потом там остаться за деньги .\n",
      "New sent prob: 6.941408410668373\n",
      "Orig sent: До конца 19 века обязательным считалось разрешение диссонанса в консонанс , в 20 веке применяют диссонансы и без их разрешения .\n",
      "Orig sent prob: 56.67218628525734\n",
      "New sent: До конца 19 века обязательным считалось разрешение диссонанса на консонанс , в 20 веке применяют диссонансы и без их разрешения .\n",
      "New sent prob: 66.77150911092758\n",
      "Orig sent: « Как же вы не верите в любовь ? ! Вы забыли как , из-за этого неверного .\n",
      "Orig sent prob: 5.290836412459612\n",
      "New sent: « Как же вы не верите в любовь ? ! Вы забыли как , кроме этого неверного .\n",
      "New sent prob: 22.776047872379422\n",
      "Orig sent: В конце страницы есть ссылки к видео-роликам о последних новостей Гринпис в области сохранения Байкала .\n",
      "Orig sent prob: 4.760550274513662\n",
      "New sent: В конце страницы есть ссылки к видео-роликам из последних новостей Гринпис в области сохранения Байкала .\n",
      "New sent prob: 16.827884912490845\n",
      "Orig sent: В музее « Исаакиевский собор » планирует показать оригинальный маятник под стеклянным покрытием .\n",
      "Orig sent prob: 17.44313683360815\n",
      "New sent: В музее « Исаакиевский собор » планирует показать оригинальный маятник со стеклянным покрытием .\n",
      "New sent prob: 28.145645573735237\n",
      "Orig sent: Например , я не могу купить Феррари , но я могу узнать все о машине , ходить в автошоу , смотреть все , что найду на интернете и т . д . , чтобы радоваться .\n",
      "Orig sent prob: 63.20128120481968\n",
      "New sent: Например , я не могу купить Феррари , но я могу узнать все о машине , ходить в автошоу , смотреть все , что найду в интернете и т . д . , чтобы радоваться .\n",
      "New sent prob: 78.1653864979744\n",
      "Orig sent: “ Глокализация ” значить , что глобальные процессы и локальные действии сочетают и работают в месте .\n",
      "Orig sent prob: -16.03957726061344\n",
      "New sent: “ Глокализация ” значить , что глобальные процессы и локальные действии сочетают и работают на месте .\n",
      "New sent prob: -1.442530319094658\n",
      "Orig sent: Читателю проекта должен понимать , что в результате распада СССР существует сложная языковая политика в нескольких бывших республик , сильно влияющая на образование .\n",
      "Orig sent prob: 15.055848706979305\n",
      "New sent: Читателю проекта должен понимать , что в результате распада СССР существует сложная языковая политика для нескольких бывших республик , сильно влияющая на образование .\n",
      "New sent prob: 25.07489576935768\n",
      "Orig sent: Правительство Хабаровска , может , по статистикам , может , по наглости , так уверен в том , что население так быстро вырастет в следующие годы , что АЭС будет нужна , чтобы выполнять нужность энергии города . » Он продолжается - « Правительство Владивостока счастливо иммено потому , что они знают , что существует федеральный закон об раздел энергии , производна во всех федеральных АЭС , и почти 30 % энергии этой АЭС будет отправлена в деревни и пригород Владивостока , из-за того , что по закону население Хабаровска не достаточна , чтобы получать всю энергию этой АЭС .\n",
      "Orig sent prob: 127.15085795894265\n",
      "New sent: Правительство Хабаровска , может , по статистикам , может , по наглости , так уверен в том , что население так быстро вырастет в следующие годы , что АЭС будет нужна , чтобы выполнять нужность энергии города . » Он продолжается - « Правительство Владивостока счастливо иммено потому , что они знают , что существует федеральный закон об раздел энергии , производна от всех федеральных АЭС , и почти 30 % энергии этой АЭС будет отправлена в деревни и пригород Владивостока , из-за того , что по закону население Хабаровска не достаточна , чтобы получать всю энергию этой АЭС .\n",
      "New sent prob: 140.0826898952946\n",
      "Orig sent: В фильме \" Цирк \" , терпимые люди советского народа берут от антагониста темнокожего ребенка , не видя в нем ничего неприемлемого .\n",
      "Orig sent prob: -2.4222434759140015\n",
      "New sent: В фильме \" Цирк \" , терпимые люди советского народа берут в антагониста темнокожего ребенка , не видя в нем ничего неприемлемого .\n",
      "New sent prob: 7.74467097222805\n",
      "Orig sent: Аренда квартир на Университете\n",
      "Orig sent prob: -25.37362039089203\n",
      "New sent: Аренда квартир в Университете\n",
      "New sent prob: -12.334553718566895\n",
      "Orig sent: Во-первых , в каждой ситуации США заявили , что лидеры этих стран являются нашими союзниками в регионе несколько лет , перед того как они ушли в отставку .\n",
      "Orig sent prob: 53.72924846410751\n",
      "New sent: Во-первых , в каждой ситуации США заявили , что лидеры этих стран являются нашими союзниками в регионе несколько лет , после того как они ушли в отставку .\n",
      "New sent prob: 75.10149586200714\n",
      "Orig sent: Экономическая составляющая : Экономия страдает от отсутствии воды и рыб .\n",
      "Orig sent prob: -3.5131256207823753\n",
      "New sent: Экономическая составляющая : Экономия страдает при отсутствии воды и рыб .\n",
      "New sent prob: 10.161588285118341\n",
      "Orig sent: Надо сказать , что другие преподаватель в кафедре также хорошие и хотят помогать мне и говорить со мной .\n",
      "Orig sent prob: 28.60433578491211\n",
      "New sent: Надо сказать , что другие преподаватель на кафедре также хорошие и хотят помогать мне и говорить со мной .\n",
      "New sent prob: 40.814862847328186\n",
      "Orig sent: Во то же время , говорит <name> , число трудоспособных в стране понижается .\n",
      "Orig sent prob: -10.006078451871872\n",
      "New sent: В то же время , говорит <name> , число трудоспособных в стране понижается .\n",
      "New sent prob: 2.717655271291733\n",
      "Orig sent: Если у них отрицательные стереотипы о американцах , сначала нам нужно преодолеть их вместе .\n",
      "Orig sent prob: 0.9326029568910599\n",
      "New sent: Если у них отрицательные стереотипы об американцах , сначала нам нужно преодолеть их вместе .\n",
      "New sent prob: 10.973406061530113\n",
      "Orig sent: Что \" Медведь \" рассказывает о своих читателей ? Вы независимы и успешный .\n",
      "Orig sent prob: -3.6439392417669296\n",
      "New sent: Что \" Медведь \" рассказывает для своих читателей ? Вы независимы и успешный .\n",
      "New sent prob: 9.643620729446411\n",
      "Orig sent: Наоборот , все , что сейчас случается в Владивостоке , кажется очень загадочным .\n",
      "Orig sent prob: 19.896219730377197\n",
      "New sent: Наоборот , все , что сейчас случается во Владивостоке , кажется очень загадочным .\n",
      "New sent prob: 34.81415915489197\n",
      "Orig sent: Куда ведёт этот экономный путь ? Всегда к профессии , даже когда студент изучает общую культуру вне ( или , возможно , внутри ) своей специальности .\n",
      "Orig sent prob: 49.69814017415047\n",
      "New sent: Куда ведёт этот экономный путь ? Всегда вне профессии , даже когда студент изучает общую культуру вне ( или , возможно , внутри ) своей специальности .\n",
      "New sent prob: 67.09622332453728\n",
      "Orig sent: Но если сравнить все эти числа со числами все страны , то они не выглядят такими большими .\n",
      "Orig sent prob: 32.83463251590729\n",
      "New sent: Но если сравнить все эти числа с числами все страны , то они не выглядят такими большими .\n",
      "New sent prob: 43.43410313129425\n",
      "Orig sent: А здесь - корова идет мимо лодки в бывшей территории моря .\n",
      "Orig sent prob: -17.565495938062668\n",
      "New sent: А здесь - корова идет мимо лодки на бывшей территории моря .\n",
      "New sent prob: -7.283469200134277\n",
      "Orig sent: Буд Кларк был очень известным , потому что перед того , как он стал мэром , он был владетелем таверна , и каждый день ездил на работе на велосипеде .\n",
      "Orig sent prob: 39.273487985134125\n",
      "New sent: Буд Кларк был очень известным , потому что до того , как он стал мэром , он был владетелем таверна , и каждый день ездил на работе на велосипеде .\n",
      "New sent prob: 56.68774372339249\n",
      "Orig sent: С распада СССР идея национальности является проблемой в России .\n",
      "Orig sent prob: 0.5582589507102966\n",
      "New sent: После распада СССР идея национальности является проблемой в России .\n",
      "New sent prob: 11.29874673485756\n",
      "Orig sent: К тому же , переводчики и лингвисты , хотя имеют место в рынке труда , не такие нужные в Америке , как в России .\n",
      "Orig sent prob: 65.45621711015701\n",
      "New sent: К тому же , переводчики и лингвисты , хотя имеют место на рынке труда , не такие нужные в Америке , как в России .\n",
      "New sent prob: 77.77545124292374\n",
      "Orig sent: Большинство идеи о американцах приходит из СМИ .\n",
      "Orig sent prob: -19.186661899089813\n",
      "New sent: Большинство идеи об американцах приходит из СМИ .\n",
      "New sent prob: -8.523598909378052\n",
      "Orig sent: При нём люди , которые уже имеют капитал или преимущества из-за места жительства , будут продолжать богатеть .\n",
      "Orig sent prob: 13.47871720790863\n",
      "New sent: При нём люди , которые уже имеют капитал или преимущества от места жительства , будут продолжать богатеть .\n",
      "New sent prob: 24.9875510931015\n",
      "Orig sent: с прихода к власти реформатора Михаила Горбачёва .\n",
      "Orig sent prob: 5.38944599032402\n",
      "New sent: После прихода к власти реформатора Михаила Горбачёва .\n",
      "New sent prob: 21.95599126815796\n",
      "Orig sent: Стена была построена , чтобы уменьшить эмиграцию в запад и также чтобы определить конкретную ( и бетонную ) границу между капиталистическим и коммунистическими странами .\n",
      "Orig sent prob: 41.42128054052591\n",
      "New sent: Стена была построена , чтобы уменьшить эмиграцию на запад и также чтобы определить конкретную ( и бетонную ) границу между капиталистическим и коммунистическими странами .\n",
      "New sent prob: 52.81292895972729\n",
      "Orig sent: Например , автор отмечает , что количество учащихся в вузах в России было два раза больше в США , хотя в то же время в США население было меньше российского на три раза .\n",
      "Orig sent prob: 92.43597574857995\n",
      "New sent: Например , автор отмечает , что количество учащихся в вузах в России было два раза больше в США , хотя в то же время в США население было меньше российского в три раза .\n",
      "New sent prob: 106.67221460863948\n",
      "Orig sent: Кажется , что дом из сказки , и когда вы видите его , рождает чувство , что это действительно замок , и вы во другом времени .\n",
      "Orig sent prob: 30.256783217191696\n",
      "New sent: Кажется , что дом из сказки , и когда вы видите его , рождает чувство , что это действительно замок , и вы в другом времени .\n",
      "New sent prob: 51.75464603304863\n",
      "Orig sent: Эксплуатация стран третьего мира от лиц с высоким ВВП тоже стала причиной этого прогресса .\n",
      "Orig sent prob: 13.45667814463377\n",
      "New sent: Эксплуатация стран третьего мира для лиц с высоким ВВП тоже стала причиной этого прогресса .\n",
      "New sent prob: 23.534115999937057\n",
      "Orig sent: Насчет гимна России , символики флага или даже герба тоже не могу не согласиться ! Больше напора в сторону патриотизма однозначно было во время Союза , а не сейчас .\n",
      "Orig sent prob: 31.191125571727753\n",
      "New sent: Без гимна России , символики флага или даже герба тоже не могу не согласиться ! Больше напора в сторону патриотизма однозначно было во время Союза , а не сейчас .\n",
      "New sent prob: 46.67814803682268\n",
      "Orig sent: Очень важно иметь таких людей , которые действительно образованы , о обеспечивании государства высокого места в международной иерархии высокоразвитых технологических стран , и которые знают , как перевести государство на второй уровень экономики , от первого , то есть от продажи нефти .\n",
      "Orig sent prob: 66.21439734846354\n",
      "New sent: Очень важно иметь таких людей , которые действительно образованы , в обеспечивании государства высокого места в международной иерархии высокоразвитых технологических стран , и которые знают , как перевести государство на второй уровень экономики , от первого , то есть от продажи нефти .\n",
      "New sent prob: 81.66559569910169\n",
      "Orig sent: Он женился для карьеры и . т . д .\n",
      "Orig sent prob: 10.869031071662903\n",
      "New sent: Он женился ради карьеры и . т . д .\n",
      "New sent prob: 25.020933866500854\n",
      "Orig sent: до крупномасштабных фашистских репрессий еврею Шейнбергу удалось иммигрировать в США , где он нашёл хорошую нишу в Университете Калифорнии в Лос-Анджелесе ( UCLA ) , где всё ещё был интерес к авангардной музыке .\n",
      "Orig sent prob: 69.55972705036402\n",
      "New sent: После крупномасштабных фашистских репрессий еврею Шейнбергу удалось иммигрировать в США , где он нашёл хорошую нишу в Университете Калифорнии в Лос-Анджелесе ( UCLA ) , где всё ещё был интерес к авангардной музыке .\n",
      "New sent prob: 81.51208674907684\n",
      "Orig sent: Просто говоря , цикл такой : воды в океане становятся облаками в атмосфере , облака становятся дождем или снегом , выпадают на землю и возвращается на океан .\n",
      "Orig sent prob: 38.67835381627083\n",
      "New sent: Просто говоря , цикл такой : воды в океане становятся облаками в атмосфере , облака становятся дождем или снегом , выпадают на землю и возвращается в океан .\n",
      "New sent prob: 50.84529563039541\n",
      "Orig sent: Они дали мне идеи , которые я обсудила на занятий со студентами .\n",
      "Orig sent prob: 23.529623180627823\n",
      "New sent: Они дали мне идеи , которые я обсудила после занятий со студентами .\n",
      "New sent prob: 39.23261886835098\n",
      "Orig sent: В Руси была похожая система , как в Европе .\n",
      "Orig sent prob: 20.09047068655491\n",
      "New sent: На Руси была похожая система , как в Европе .\n",
      "New sent prob: 31.19927543401718\n",
      "Orig sent: Я всё ещё пишу музыку в каждых выходных .\n",
      "Orig sent prob: 7.646516636013985\n",
      "New sent: Я всё ещё пишу музыку для каждых выходных .\n",
      "New sent prob: 24.278582245111465\n",
      "Orig sent: Статья рассчитана для любого образованного читателя .\n",
      "Orig sent prob: 4.911538869142532\n",
      "New sent: Статья рассчитана на любого образованного читателя .\n",
      "New sent prob: 16.174056500196457\n",
      "Orig sent: Эти названия профессий встречаются не только в разговорной или письменной речи , а в многих разных стилях речи .\n",
      "Orig sent prob: 40.74967214465141\n",
      "New sent: Эти названия профессий встречаются не только в разговорной или письменной речи , а во многих разных стилях речи .\n",
      "New sent prob: 54.1121876090765\n",
      "Orig sent: Другую важную адаптацию в России вызвала потребность к бутылочной воде .\n",
      "Orig sent prob: -9.991296529769897\n",
      "New sent: Другую важную адаптацию в России вызвала потребность в бутылочной воде .\n",
      "New sent prob: 1.7839550375938416\n",
      "Orig sent: Мексика и Америка находятся в достаточно тесный отношениях в рынке труда .\n",
      "Orig sent prob: 8.98254656791687\n",
      "New sent: Мексика и Америка находятся в достаточно тесный отношениях на рынке труда .\n",
      "New sent prob: 21.91016172617674\n",
      "Orig sent: Говорится в статьи , что глобализация - мощный и стихийный процесс - я согласен .\n",
      "Orig sent prob: 4.83374297618866\n",
      "New sent: Говорится из статьи , что глобализация - мощный и стихийный процесс - я согласен .\n",
      "New sent prob: 16.076906710863113\n",
      "Orig sent: На принципе желания отличать себя от западныХ , капиталистическиХ странам , Советская Россия избегала \" западнОГО \" терминА Арт-Деко .\n",
      "Orig sent prob: -67.73501858115196\n",
      "New sent: На принципе желания отличать себя по западныХ , капиталистическиХ странам , Советская Россия избегала \" западнОГО \" терминА Арт-Деко .\n",
      "New sent prob: -49.01011274755001\n",
      "Orig sent: Всё это происходит в пяти минут ходьбы от мэрии и здания МВД и десяти минут от Кремля .\n",
      "Orig sent prob: 42.837345976382494\n",
      "New sent: Всё это происходит около пяти минут ходьбы от мэрии и здания МВД и десяти минут от Кремля .\n",
      "New sent prob: 53.32558289170265\n",
      "Orig sent: Естественно , что в путеводители не обязательно подробно говорить о истории , и этот момент не показывает , что авторы безответственно работали .\n",
      "Orig sent prob: 15.256509512662888\n",
      "New sent: Естественно , что в путеводители не обязательно подробно говорить об истории , и этот момент не показывает , что авторы безответственно работали .\n",
      "New sent prob: 25.525920532643795\n",
      "Orig sent: до распада СССР в 1991 г .\n",
      "Orig sent prob: 19.23976969718933\n",
      "New sent: После распада СССР в 1991 г .\n",
      "New sent prob: 29.90365958213806\n",
      "Orig sent: Учебники недостаточны , учителей не имеют правильную подготовку , и у детей нет выбора в многих школах , потому что либо нет интереса в других модулях , либо в школах нет денег для изучения каждого модуля .\n",
      "Orig sent prob: 80.98138898611069\n",
      "New sent: Учебники недостаточны , учителей не имеют правильную подготовку , и у детей нет выбора во многих школах , потому что либо нет интереса в других модулях , либо в школах нет денег для изучения каждого модуля .\n",
      "New sent prob: 92.00102369114757\n",
      "Orig sent: Кроме географического положения , Северная Америка имеет больше связи с Европой по расовому наследстве , истории , экономике , политике и культур , чем Россия .\n",
      "Orig sent prob: 47.16052580624819\n",
      "New sent: Кроме географического положения , Северная Америка имеет больше связи с Европой в расовому наследстве , истории , экономике , политике и культур , чем Россия .\n",
      "New sent prob: 58.40005326271057\n",
      "Orig sent: Как видно в примере популярного писателя Чака Паланюка , любой академический предмет может , в конце концов , привести к неожиданной , вторичной ( или даже третичной ) профессии , поэтому вот это причина , по которой в Америке студенты обязаны изучать общеобразовательные предметы рядом с предметами своей специальности .\n",
      "Orig sent prob: 95.20996324717999\n",
      "New sent: Как видно на примере популярного писателя Чака Паланюка , любой академический предмет может , в конце концов , привести к неожиданной , вторичной ( или даже третичной ) профессии , поэтому вот это причина , по которой в Америке студенты обязаны изучать общеобразовательные предметы рядом с предметами своей специальности .\n",
      "New sent prob: 106.7903850749135\n",
      "Orig sent: Через дня , радиационный фон превышал на 87 раз .\n",
      "Orig sent prob: -13.898165106773376\n",
      "New sent: Через дня , радиационный фон превышал в 87 раз .\n",
      "New sent prob: -0.045717835426330566\n",
      "Orig sent: Начался новый период в истории российской монархии ; этот период длился с 1907 г .\n",
      "Orig sent prob: 24.34173533320427\n",
      "New sent: Начался новый период в истории российской монархии ; этот период длился до 1907 г .\n",
      "New sent prob: 34.79279202222824\n",
      "Orig sent: На этом я передаю слово <Name> .\n",
      "Orig sent prob: -17.54609453678131\n",
      "New sent: При этом я передаю слово <Name> .\n",
      "New sent prob: -5.95614218711853\n",
      "Orig sent: Мы стараемся понять погодные явления и в результате разделить наш мир в эти так называемый климатические зоны .\n",
      "Orig sent prob: 24.013666719198227\n",
      "New sent: Мы стараемся понять погодные явления и в результате разделить наш мир на эти так называемый климатические зоны .\n",
      "New sent prob: 42.832772250287235\n",
      "Orig sent: Но ясно , что у нее доброе сердце , потому что она заботится о успехе студентов и кафедре .\n",
      "Orig sent prob: 33.48416164517403\n",
      "New sent: Но ясно , что у нее доброе сердце , потому что она заботится об успехе студентов и кафедре .\n",
      "New sent prob: 43.736282140016556\n",
      "Orig sent: При этом культурном обмене русское почтительное отношение к власти углублялось , что конечном счёте привело к доминированию советской власти в ХХ в .\n",
      "Orig sent prob: 11.002730697393417\n",
      "New sent: В этом культурном обмене русское почтительное отношение к власти углублялось , что конечном счёте привело к доминированию советской власти в ХХ в .\n",
      "New sent prob: 25.922004356980324\n",
      "Orig sent: Мексика и Америка находятся в достаточно тесных отношениях в рынке труда .\n",
      "Orig sent prob: 20.419275641441345\n",
      "New sent: Мексика и Америка находятся в достаточно тесных отношениях на рынке труда .\n",
      "New sent prob: 34.071859419345856\n",
      "Orig sent: Город Магадан — отдалённый ; он находится на бухте Нагаево , на Дальнем Востоке России .\n",
      "Orig sent prob: 20.504754543304443\n",
      "New sent: Город Магадан — отдалённый ; он находится в бухте Нагаево , на Дальнем Востоке России .\n",
      "New sent prob: 33.27795326709747\n",
      "Orig sent: Каждый курс рассчитан на 34 часа , и в конце предмета на основе изученного материала ученики из каждого курса подготовят презентацию и представляют свой проект на всех учеников 4-ого и 5-ого классов .\n",
      "Orig sent prob: 83.30793388932943\n",
      "New sent: Каждый курс рассчитан на 34 часа , и в конце предмета на основе изученного материала ученики из каждого курса подготовят презентацию и представляют свой проект для всех учеников 4-ого и 5-ого классов .\n",
      "New sent prob: 99.48962639272213\n",
      "Orig sent: Коммунизм и советский социализм в идеале хотели использовать навыки , таланты и работу каждого человека , чтобы собирать всю человеческую силу за благо всего общества .\n",
      "Orig sent prob: 37.581163078546524\n",
      "New sent: Коммунизм и советский социализм в идеале хотели использовать навыки , таланты и работу каждого человека , чтобы собирать всю человеческую силу на благо всего общества .\n",
      "New sent prob: 50.19717698357999\n",
      "Orig sent: После обсуждения все члены городского государства Владивостока встретились , чтобы договориться на официальной реакции города Владивосток к вчерашнему решению о АЭС .\n",
      "Orig sent prob: 7.170825339853764\n",
      "New sent: После обсуждения все члены городского государства Владивостока встретились , чтобы договориться об официальной реакции города Владивосток к вчерашнему решению о АЭС .\n",
      "New sent prob: 22.14022848010063\n",
      "Orig sent: Представители общественности тоже задали вопросы без решении .\n",
      "Orig sent prob: -21.05205535888672\n",
      "New sent: Представители общественности тоже задали вопросы о решении .\n",
      "New sent prob: 11.99707680940628\n",
      "Orig sent: У Портленде есть своя система городского самоуправления .\n",
      "Orig sent prob: 5.716810554265976\n",
      "New sent: В Портленде есть своя система городского самоуправления .\n",
      "New sent prob: 17.977176047861576\n",
      "Orig sent: Если от слабости морали политик не может решить проблему и действовать в соответствии с интересами народа , народ не может ему доверять .\n",
      "Orig sent prob: 58.570926785469055\n",
      "New sent: Если при слабости морали политик не может решить проблему и действовать в соответствии с интересами народа , народ не может ему доверять .\n",
      "New sent prob: 69.83313784003258\n",
      "Orig sent: Напряжение начало в оккупированных зонах Германии , которые были разделены на две части : \" западную \" Федеративную Республику Германую и коммунистическую \" Германскую Демократическую Партию . \" \" Отсюда , противоположение запада СССР и , наоборот , стало очевидно в многих международных делах , как в их участии в Корейской войне и в национально-освободительных движения в Африке и Южной Америке .\n",
      "Orig sent prob: 89.51212800294161\n",
      "New sent: Напряжение начало в оккупированных зонах Германии , которые были разделены на две части : \" западную \" Федеративную Республику Германую и коммунистическую \" Германскую Демократическую Партию . \" \" Отсюда , противоположение запада СССР и , наоборот , стало очевидно во многих международных делах , как в их участии в Корейской войне и в национально-освободительных движения в Африке и Южной Америке .\n",
      "New sent prob: 102.3033540956676\n",
      "Orig sent: Она ходит по комнате за окно , и либо она читает , либо говорит по телефону .\n",
      "Orig sent prob: 38.11668848991394\n",
      "New sent: Она ходит по комнате через окно , и либо она читает , либо говорит по телефону .\n",
      "New sent prob: 60.64786434173584\n",
      "Orig sent: Например , ученые недавно обнаружили новый вид бактерий на дну Байкала , которые едят Байкальскую нефть .\n",
      "Orig sent prob: 22.738113939762115\n",
      "New sent: Например , ученые недавно обнаружили новый вид бактерий по дну Байкала , которые едят Байкальскую нефть .\n",
      "New sent prob: 33.14071395993233\n",
      "Orig sent: Я хочу построить хорошее отношение с своими коллегами , поэтому мне надо обращать внимание на то , что мешается в это отношение .\n",
      "Orig sent prob: 43.29508709907532\n",
      "New sent: Я хочу построить хорошее отношение со своими коллегами , поэтому мне надо обращать внимание на то , что мешается в это отношение .\n",
      "New sent prob: 53.84079420566559\n",
      "Orig sent: Я пришел в выводу , что религия больше , чем социальное явления или способ политического контроля .\n",
      "Orig sent prob: 19.112500220537186\n",
      "New sent: Я пришел к выводу , что религия больше , чем социальное явления или способ политического контроля .\n",
      "New sent prob: 30.49609462171793\n",
      "Orig sent: Ради этого я жила в России четыре месяца и планирую вернуться туда на год .\n",
      "Orig sent prob: 25.459430158138275\n",
      "New sent: До этого я жила в России четыре месяца и планирую вернуться туда на год .\n",
      "New sent prob: 35.542846247553825\n",
      "Orig sent: Чхартишвили окончил историко-филологическое отделение Института стран Азии и Африки в МГУ .\n",
      "Orig sent prob: -12.113512516021729\n",
      "New sent: Чхартишвили окончил историко-филологическое отделение Института стран Азии и Африки при МГУ .\n",
      "New sent prob: 4.087726026773453\n",
      "Orig sent: Даже перед того , как видела эту сцену , я знала , что должно происходить .\n",
      "Orig sent prob: 30.641615748405457\n",
      "New sent: Даже после того , как видела эту сцену , я знала , что должно происходить .\n",
      "New sent prob: 54.77656734455377\n",
      "Orig sent: Во времени войны было сложно путешествовать в восточной Европе .\n",
      "Orig sent prob: 7.343004658818245\n",
      "New sent: Ко времени войны было сложно путешествовать в восточной Европе .\n",
      "New sent prob: 19.72600269317627\n",
      "Orig sent: Хотя многие бы сказали , что первый человек эмигрировал сам по воли , мало согласилось бы с тем , что второй человек тоже переехал добровольно .\n",
      "Orig sent prob: 49.64673659205437\n",
      "New sent: Хотя многие бы сказали , что первый человек эмигрировал сам против воли , мало согласилось бы с тем , что второй человек тоже переехал добровольно .\n",
      "New sent prob: 67.94745322689414\n",
      "Orig sent: В обеих фильмах , ситуация решена в музыкальном номере , где герои поют о блага разнообразного мира .\n",
      "Orig sent prob: 10.617428429424763\n",
      "New sent: В обеих фильмах , ситуация решена в музыкальном номере , где герои поют для блага разнообразного мира .\n",
      "New sent prob: 35.340113546699286\n",
      "Orig sent: Я не эксперт по этой области , но я считаю , что никто не самом деле ничего не узнает на таких курсах .\n",
      "Orig sent prob: 42.277039708569646\n",
      "New sent: Я не эксперт в этой области , но я считаю , что никто не самом деле ничего не узнает на таких курсах .\n",
      "New sent prob: 53.31543745845556\n",
      "Orig sent: Я не считаю произведения Айн Рэнд художественной литературой , а полемикой - то есть ее главная цель не была написать вымышленную фантазию , а пропагандировать капиталистические индивидуалистические идеи через реалистичной борьбы человеческого творчеста против коллектива .\n",
      "Orig sent prob: 5.653508838266134\n",
      "New sent: Я не считаю произведения Айн Рэнд художественной литературой , а полемикой - то есть ее главная цель не была написать вымышленную фантазию , а пропагандировать капиталистические индивидуалистические идеи посредством реалистичной борьбы человеческого творчеста против коллектива .\n",
      "New sent prob: 20.601670622825623\n",
      "Orig sent: В сути , они были террористами .\n",
      "Orig sent prob: 7.819805145263672\n",
      "New sent: По сути , они были террористами .\n",
      "New sent prob: 22.506919965147972\n",
      "Orig sent: И пресная , и соленая вода используется в многих разных областях .\n",
      "Orig sent prob: 23.08689507842064\n",
      "New sent: И пресная , и соленая вода используется во многих разных областях .\n",
      "New sent prob: 38.4908629655838\n",
      "Orig sent: В современном обществе в протяжении своей жизни взрослые часто проходят через несколько профессиональных студий , иногда сменяя свою профессию 3-4 раза .\n",
      "Orig sent prob: 42.159152161329985\n",
      "New sent: В современном обществе на протяжении своей жизни взрослые часто проходят через несколько профессиональных студий , иногда сменяя свою профессию 3-4 раза .\n",
      "New sent prob: 58.587057396769524\n",
      "Orig sent: Сегодня инновационные компании множат способы адаптации к новым рынкам , то есть компания должен постоянно улучшает свой продукт , а также найдёт новые рынки , например , на интернете , в других регионах , странах и так далее .\n",
      "Orig sent prob: 60.62053856253624\n",
      "New sent: Сегодня инновационные компании множат способы адаптации к новым рынкам , то есть компания должен постоянно улучшает свой продукт , а также найдёт новые рынки , например , в интернете , в других регионах , странах и так далее .\n",
      "New sent prob: 75.01581907272339\n",
      "Orig sent: Я считаю , что в России больше ударились в развлекательные программы .\n",
      "Orig sent prob: 9.11955027282238\n",
      "New sent: Я считаю , что в России больше ударились на развлекательные программы .\n",
      "New sent prob: 19.45844566822052\n",
      "Orig sent: По-моему , мне очень важно помнить , что речь идет о образовании .\n",
      "Orig sent prob: 35.17453795671463\n",
      "New sent: По-моему , мне очень важно помнить , что речь идет об образовании .\n",
      "New sent prob: 46.659876704216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# без удаления предлога\n",
    "for j,(sent,ind) in tqdm(enumerate(zip(test_orig, indices))):\n",
    "    for i in ind:\n",
    "        sub = get_alternate_words(sentence=sent, \n",
    "                    word_index=i,\n",
    "                    bert_tokenizer=bert_tokenizer,\n",
    "                    bert_model=bert_model,\n",
    "                    top=1)[0][0]\n",
    "        if sub.lower() in rus_preps and sub != sent.split()[i]:\n",
    "            orig_prob = sentence_prob(sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model)\n",
    "            tmp = sent.split()\n",
    "            tmp[i] = sub\n",
    "            new_sent = ' '.join(tmp)\n",
    "            new_prob = sentence_prob(new_sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model)\n",
    "            thr = 10\n",
    "            if new_prob > (orig_prob + thr):\n",
    "                print('Orig sent: {}'.format(sent))\n",
    "                print('Orig sent prob: {}'.format(orig_prob))\n",
    "                print('New sent: {}'.format(new_sent))\n",
    "                print('New sent prob: {}'.format(new_prob))\n",
    "                test_orig[j] = sent = new_sent\n",
    "    with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/RULEC-GEC_test_ya_speller_punct_comma-masked-no-lowercase_prep-masked.txt', 'a', encoding='utf8') as f:\n",
    "        print(sent, file=f, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Перебор словоформ существительных из предложных групп рубертом (skills_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/RULEC-GEC_test_ya_speller_punct_comma-masked-no-lowercase_prep-masked_parsed.txt',\n",
    "         'r') as f:\n",
    "    test_ya_parsed = f.read()\n",
    "sents = test_ya_parsed.split('\\n\\n')\n",
    "del sents[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4a857d7e6b4000a5e12f3e6327e4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4993.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В частности , в 2086 году .\n",
      "Есть возможность , что представителей Гуманитарного Действия приедут в город Вашингтон летом и , лучше всего , в Портленд в ноябре ! Я сказала , что я готова переводить для них и работать экскурсоводом , если на самом деле приедут в нашей замечательный город .\n",
      "Потом я устроился на работу , и всё было хорошо .\n",
      "Тамилой рассказывает Пете о своем напитке от всех злах и страданий , о своем кольце с жабой , которое ее бережет , о птице Сирин - птица смерти , о птице Финист , и Алконост , и дарит Пете волшебное редкое яйцо Алконоста .\n",
      "Первостепенное доказательство того , что эти красноармейцы – бандиты , появляется рано в поэме , к концу части 2 , где Блок описывает их словами : « В зубах – цыгарка , примят картуз , / / На спинах б надо бубновый туз ! » .\n",
      "В процессе этого эксперимента руководители и финансовые лидеры проекта проводят другие реформы , которые решают проблемы с коррупцией и привлекают иностранных специалистов или собственных , отечественных талантов обратно в Россию .\n",
      "IndexError\n",
      "“ Путин указал , что входящие в ВТО развитые страны все чаще придерживаются политики протекционизма , против которого была призвана бороться ВТО . ” По материялам Би-би-си >\n",
      "Царские власти были более терпимыми в отношении буддистов .\n",
      "В среде иностранцев появились интересные « касты » для разных видов работ .\n",
      "От этой базы , я могу создавать что-то новый и давать то , что студентам нужно .\n",
      "Западные капиталистические страны беспокоились о том , что СССР стремился вмешать в дела других стран и установить диктатуру пролетариата по всему миру .\n",
      "В сегодняшние дни в Америке есть больше 1750 пивоварений и с валовой стоимостью доллара более 7 миллиардов .\n",
      "IndexError\n",
      "Вследствие этого бывшие имперские территории за океанами мало отражают черты своих бывших западно-европейских правителей , а российские территории в Сибири и Дальнем Востоке продолжали культурный обмен с русскими и стали более похожими на европейскую Россию .\n",
      "IndexError\n",
      "Но когда обращают внимание на русских , появляется какое-то чувство , что они гораздо ближе к нам .\n",
      "IndexError\n",
      "Наши талантливые студенты развивают свои собственные интересы : они в академическом хоре , играют за нашу баскетбольную комадну , выступают в спектаклях театральной студии и много много еще .\n",
      "IndexError\n",
      "« Россия для русских ! »\n",
      "Было неофициально обещано открытие нового университета энергических наук в Хабаровске , и представители районных властей бесстыдно сразу согласились с этим подходом к « сотрудничествам » после этого предложения .\n",
      "Общество влияет огромно на судьбу каждого человека - но человек может решить , что делать в каждом случае .\n",
      "Люди тянутся к этой пьесе не только для того , чтобы пойти на светский раут .\n",
      "Главное утверждение эссе – если собстенное поведение каждого человека не изменить , чтобы ухажевать за природой , то мы наносим ущерб хрупкому балансу жизни на Земле .\n",
      "IndexError\n",
      "С 13 лет молодой Горбачёв совмещал учёбу в школе с периодической работой в машинно-тракторной станции и в колхозе в Ставропо́льском кра́е .\n",
      "В результате проведения исследования ожидаются общая картина влияния языковой политикой на образование , и анализ успешных и не успешных подходов к образованию в постсоветское время .\n",
      "IndexError\n",
      "в селе Привольное , в Ставропо́льском кра́е .\n",
      "IndexError\n",
      "Они влияют на человекa , если он умеет критически мыслить , они не противоречат процесс мышления , взаимодействуют с ним .\n",
      "При виде этого здания красота и необычность не только привлекают внимание , но и порождают чувство давно минувшего времени .\n",
      "IndexError\n",
      "К еде и здоровью отношение у русских такое – у них нет желания пожить без болезней , по мнению русских врачей .\n",
      "Историческое основание разделения между Русской православной церковью и Российским правительством .\n",
      "Таким образом , каждый из учеников имеют возможность узнать обо всех курсах .\n",
      "Многие из самых известных движений и лидеров в русской истории приняли свои идеи из европейской культуры .\n",
      "Так же геополитика рассматривается как наука о значении географического положения в политических стратегиях того или иного государства , и реализации этих стратегий в своей истории .\n",
      "Кажется , что студенты , в роли потребителей , более вероятно , купить товары из других стран .\n",
      "Так как эта работа не занимает слишком много времени - только несколько часов в неделю - я хочу продолжить её после того , как вернусь в США .\n",
      "Правительство Хабаровска , может , по статистике , может , по наглости , так уверен в том , что население так быстро вырастет в следующие годы , что АЭС будет нужна , чтобы выполнять нужность энергии города . » Он продолжается - « Правительство Владивостока счастливо иммено потому , что они знают , что существует федеральный закон об раздел энергии , производна от всех федеральных АЭС , и почти 30 % энергии этой АЭС будет отправлена в деревни и пригород Владивостока , из-за того , что по закону население Хабаровска не достаточна , чтобы получать всю энергию этой АЭС .\n"
     ]
    }
   ],
   "source": [
    "for sent in tqdm(sents):\n",
    "    spl = sent.split('\\n')\n",
    "    synt_info = [x.split('\\t') for x in spl]\n",
    "    orig_sent = ' '.join(x[1] for x in synt_info)\n",
    "    i = 0\n",
    "    while i < len(synt_info):\n",
    "        tok = synt_info[i]\n",
    "        if (tok[3] == 'ADP') and (tok[7] == 'case') and (synt_info[int(tok[6])-1][3] == 'NOUN'):\n",
    "            lexem = morph.parse(synt_info[int(tok[6])-1][2])\n",
    "            try:\n",
    "                lex = [x for x in lexem if 'NOUN' in x.tag and 'nomn' in x.tag][0]\n",
    "            except IndexError:\n",
    "                print('IndexError')\n",
    "                print(orig_sent)\n",
    "                i += 1\n",
    "                continue\n",
    "            hyp = {l.word for l in lex.lexeme if l.tag.POS == lex.tag.POS}\n",
    "            orig_prob = sentence_prob(orig_sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model,\n",
    "                                                  batch_size=16)\n",
    "            new_probs = dict()\n",
    "            for h in hyp:\n",
    "                if synt_info[int(tok[6])-1][0].isupper():\n",
    "                    h = h.capitalize()\n",
    "                tmp = orig_sent.split()\n",
    "                tmp[int(synt_info[int(tok[6])-1][0]) - 1] = h\n",
    "                new_sent = ' '.join(tmp)\n",
    "                new_prob = sentence_prob(new_sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model)\n",
    "                new_probs[str(new_prob)] = new_sent\n",
    "            thr = 10\n",
    "            new_dict = {k:v for (k,v) in new_probs.items() if float(k) > (orig_prob + thr)}\n",
    "            if not new_dict:\n",
    "                i += 1\n",
    "                continue\n",
    "            max_item = max(new_dict.items(), key=lambda x: float(x[0]))\n",
    "            orig_sent = max_item[1]\n",
    "            print(orig_sent)\n",
    "        i += 1\n",
    "    with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/RULEC-GEC_test_ya_speller_punct_comma-masked_prep-masked_noun-masked-test.txt', 'a', encoding='utf8') as f:\n",
    "        print(orig_sent, file=f, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исправление по фреймбанку с перебором рубертом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = pd.read_csv('framebank_dict_cx_items.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranks = set(frames['Rank'])\n",
    "# forms = list(set(frames['Form']))\n",
    "grams = {'Sacc': ['NOUN', 'Case=Acc'],\n",
    "        'Sdat': ['NOUN', 'Case=Dat'],\n",
    "        'Sgen': ['NOUN', 'Case=Gen'],\n",
    "        'Sins': ['NOUN', 'Case=Ins'],\n",
    "        'Sloc': ['NOUN', 'Case=Loc'],\n",
    "        'Snom': ['NOUN', 'Case=Nom']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame = frames.groupby('ConstrIndex', as_index=False).agg({'Form': list,\n",
    "                                                               'Rank': list,\n",
    "                                                   'KeyLexemes': 'first'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ConstrIndex</th>\n",
       "      <th>Form</th>\n",
       "      <th>Rank</th>\n",
       "      <th>KeyLexemes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10766</th>\n",
       "      <td>10766</td>\n",
       "      <td>11924</td>\n",
       "      <td>[Snom, угрожать, Sdat, Sins]</td>\n",
       "      <td>[Субъект, Предикат, Периферия, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10767</th>\n",
       "      <td>10767</td>\n",
       "      <td>11925</td>\n",
       "      <td>[Snom, угрожать, что + CL]</td>\n",
       "      <td>[Субъект, Предикат, Клауза]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10768</th>\n",
       "      <td>10768</td>\n",
       "      <td>11926</td>\n",
       "      <td>[Snom, угрожать, Sdat]</td>\n",
       "      <td>[Субъект, Предикат, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10769</th>\n",
       "      <td>10769</td>\n",
       "      <td>11927</td>\n",
       "      <td>[Snom, угрожать, Sdat, Sins]</td>\n",
       "      <td>[Субъект, Предикат, Периферия, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10770</th>\n",
       "      <td>10770</td>\n",
       "      <td>11928</td>\n",
       "      <td>[Snom, угрожать, Vinf]</td>\n",
       "      <td>[Субъект, Предикат, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10771</th>\n",
       "      <td>10771</td>\n",
       "      <td>11929</td>\n",
       "      <td>[Snom, угрожать, Sdat]</td>\n",
       "      <td>[Субъект, Предикат, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10857</th>\n",
       "      <td>10857</td>\n",
       "      <td>12028</td>\n",
       "      <td>[Snom, угрожать]</td>\n",
       "      <td>[Субъект, Предикат]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12438</th>\n",
       "      <td>12438</td>\n",
       "      <td>13862</td>\n",
       "      <td>[Snom, угрожать, Sdat]</td>\n",
       "      <td>[Субъект, Предикат, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12439</th>\n",
       "      <td>12439</td>\n",
       "      <td>13863</td>\n",
       "      <td>[Snom, угрожать, Vinf]</td>\n",
       "      <td>[Субъект, Предикат, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12440</th>\n",
       "      <td>12440</td>\n",
       "      <td>13864</td>\n",
       "      <td>[Snom, угрожать, Sdat]</td>\n",
       "      <td>[Субъект, Предикат, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>12441</td>\n",
       "      <td>13865</td>\n",
       "      <td>[Vinf, угрожать, Sdat]</td>\n",
       "      <td>[Субъект, Предикат, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12442</th>\n",
       "      <td>12442</td>\n",
       "      <td>13866</td>\n",
       "      <td>[Snom, угрожать, Sdat, {Conj + CL / CL }]</td>\n",
       "      <td>[Субъект, Предикат, Периферия, Клауза]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>12443</td>\n",
       "      <td>13867</td>\n",
       "      <td>[Snom, угрожать, Sdat, Sins]</td>\n",
       "      <td>[Субъект, Предикат, Периферия, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12444</th>\n",
       "      <td>12444</td>\n",
       "      <td>13868</td>\n",
       "      <td>[Snom, угрожать, Sins]</td>\n",
       "      <td>[Субъект, Предикат, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445</th>\n",
       "      <td>12445</td>\n",
       "      <td>13869</td>\n",
       "      <td>[Snom, угрожать, Sins]</td>\n",
       "      <td>[Субъект, Предикат, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12446</th>\n",
       "      <td>12446</td>\n",
       "      <td>13870</td>\n",
       "      <td>[Snom, угрожать, {ADV / PRоткуда + Sx}, Sdat]</td>\n",
       "      <td>[Субъект, Предикат, Периферия, Периферия]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16875</th>\n",
       "      <td>16875</td>\n",
       "      <td>18472</td>\n",
       "      <td>[Snom, угрожать]</td>\n",
       "      <td>[Субъект, Предикат]</td>\n",
       "      <td>угрожать</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  ConstrIndex                                           Form  \\\n",
       "10766  10766        11924                   [Snom, угрожать, Sdat, Sins]   \n",
       "10767  10767        11925                     [Snom, угрожать, что + CL]   \n",
       "10768  10768        11926                         [Snom, угрожать, Sdat]   \n",
       "10769  10769        11927                   [Snom, угрожать, Sdat, Sins]   \n",
       "10770  10770        11928                         [Snom, угрожать, Vinf]   \n",
       "10771  10771        11929                         [Snom, угрожать, Sdat]   \n",
       "10857  10857        12028                               [Snom, угрожать]   \n",
       "12438  12438        13862                         [Snom, угрожать, Sdat]   \n",
       "12439  12439        13863                         [Snom, угрожать, Vinf]   \n",
       "12440  12440        13864                         [Snom, угрожать, Sdat]   \n",
       "12441  12441        13865                         [Vinf, угрожать, Sdat]   \n",
       "12442  12442        13866      [Snom, угрожать, Sdat, {Conj + CL / CL }]   \n",
       "12443  12443        13867                   [Snom, угрожать, Sdat, Sins]   \n",
       "12444  12444        13868                         [Snom, угрожать, Sins]   \n",
       "12445  12445        13869                         [Snom, угрожать, Sins]   \n",
       "12446  12446        13870  [Snom, угрожать, {ADV / PRоткуда + Sx}, Sdat]   \n",
       "16875  16875        18472                               [Snom, угрожать]   \n",
       "\n",
       "                                            Rank KeyLexemes  \n",
       "10766  [Субъект, Предикат, Периферия, Периферия]   угрожать  \n",
       "10767                [Субъект, Предикат, Клауза]   угрожать  \n",
       "10768             [Субъект, Предикат, Периферия]   угрожать  \n",
       "10769  [Субъект, Предикат, Периферия, Периферия]   угрожать  \n",
       "10770             [Субъект, Предикат, Периферия]   угрожать  \n",
       "10771             [Субъект, Предикат, Периферия]   угрожать  \n",
       "10857                        [Субъект, Предикат]   угрожать  \n",
       "12438             [Субъект, Предикат, Периферия]   угрожать  \n",
       "12439             [Субъект, Предикат, Периферия]   угрожать  \n",
       "12440             [Субъект, Предикат, Периферия]   угрожать  \n",
       "12441             [Субъект, Предикат, Периферия]   угрожать  \n",
       "12442     [Субъект, Предикат, Периферия, Клауза]   угрожать  \n",
       "12443  [Субъект, Предикат, Периферия, Периферия]   угрожать  \n",
       "12444             [Субъект, Предикат, Периферия]   угрожать  \n",
       "12445             [Субъект, Предикат, Периферия]   угрожать  \n",
       "12446  [Субъект, Предикат, Периферия, Периферия]   угрожать  \n",
       "16875                        [Субъект, Предикат]   угрожать  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_frame[new_frame['KeyLexemes'].str.contains(\"угрожать\")]\n",
    "# test_fr = new_frame[new_frame['KeyLexemes'].str.contains(\"угрожать\")]['Form'].tolist()\n",
    "# test_lx = new_frame[new_frame['KeyLexemes'].str.contains(\"угрожать\")]['KeyLexemes'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "def forms_and_roles(forms, roles):\n",
    "    return [(x,y) for x,y in zip(forms, roles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old (working)\n",
    "def make_patterns(patterns):\n",
    "    for i in range(len(patterns)):\n",
    "        for j in range(len(patterns[i])):\n",
    "            if '+' in patterns[i][j]:\n",
    "                patterns[i][j] = patterns[i][j].split(' + ')\n",
    "    l = []\n",
    "    for item in patterns:\n",
    "        new_item = []\n",
    "        for word in item:\n",
    "            if isinstance(word, str):\n",
    "                new_item.append(word)\n",
    "            else:\n",
    "                new_item.extend(word)\n",
    "        l.append(new_item)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp2pymorphy = {'Nom':'nomn', 'Gen':'gent', 'Dat':'datv', 'Acc':'accs', 'Ins':'ablt', 'Loc':'loct', 'Voc':'voct',\n",
    "               'Par':'gen2', 'Sing':'sing', 'Plur':'plur', 'Masc':'masc', 'Fem':'femn', 'Neut':'neut', 'Sup':'Supr',\n",
    "                 'Anim':'anim', 'Inan':'inan', 'Short':'ADJS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "disambigious_preps = {'на', 'в', 'за', 'с', 'через', 'со', 'для', 'под'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "obliq = ['Sgen', 'Sdat', 'Sacc', 'Sins', 'Sloc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/RULEC-GEC_test_ya_speller_punct_comma-masked-no-lowercase_prep-masked_prep-noun-masked_prep-noun-agr_parsed.txt',\n",
    "         'r') as f:\n",
    "    test_ya_parsed = f.read()\n",
    "test_parsed = test_ya_parsed.split('\\n\\n')\n",
    "del test_parsed[-1]\n",
    "sents = test_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcbe2f470134a0f99769233073fdf47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4993.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Человека только нужно уметь чувствовать , и , смотря на картину или читая красивые стихи , его эмоциональный интеллект .\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Хлеба будет много , голод остается досадам капитализма .\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Они не сознает , почему это грозит их жизням .\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Это был первый журнал в России , написанные толькою для мужчин , и остаётся пионером .\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Как языковая политика влияет на системы образования в бывших республиках СССР ?\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Читатель проекта должен понимать , что в результате распада СССР существует сложная языковая политика для нескольких бывших республик , сильно влияющая на образование .\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Кроме географического положения , Северная Америка умеет больше связей с Европой по антропологии , истории , экономике , политике и культуре …\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "На сайте можно найти много информации об играющей на нем музыке .\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "IndexError\n",
      "В то же время азиатские территории , завоёванные русскими , были связаны землёй с главной европейской частью Российской империи , поэтому России удалось связать и сохранить эти территории .\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Катастрофа показала , что нефтяная промышленность может добывать нефть из глубины морей , но компании не знают , как реагировать и предупреждать несчастные случаи .\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "IndexError\n",
      "Если да , какие подходи пытают / попытали ? Успешные ли они ? Какие проблемы есть ?\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Катастрофа показала , что нефтяная промышленность может добывать нефть из глубины морской среды , но компании не знают , как реагировать и предупреждать несчастные случаи .\n",
      "IndexError\n",
      "Русских не пускают – это эксклюзивно киргизкое общежитие .\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "IndexError\n",
      "исследования : 75 % населения России считают себя православных , 5 % мусульман , 1 % буддистов , больше 1 % иудейских и 8 % неверующих .\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Конечно , придётся представлять себе , разве такие же националистические чувства , которые сейчас владеют политикой в Америке , против иммигрантов , будут когда-то меняться .\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "Нет такого индекса в словаре\n",
      "IndexError\n",
      "Значит , одна АЭС может обслужить больше 1 мн .\n",
      "« Хоть и не красавица » - название первой главы из песни « родина » , написана рок - группой ДДТ .\n",
      "Многие формы экологического кризиса угрожают миру от глобального потепления .\n",
      "Нет такого индекса в словаре\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#verb-noun case agreement for noun\n",
    "\n",
    "for sent in tqdm(sents):\n",
    "    spl = sent.split('\\n')\n",
    "    synt_info = [x.split('\\t') for x in spl]\n",
    "    orig_sent = ' '.join(x[1] for x in synt_info)\n",
    "    deps = [synt_info[i][0] for i in range(len(synt_info))]\n",
    "    heads = [synt_info[i][6] for i in range(len(synt_info))]\n",
    "    heads_deps = defaultdict(set)\n",
    "    for h, d in zip(heads, deps):\n",
    "        heads_deps[h].add(d)\n",
    "    hd = dict(heads_deps)\n",
    "    i = 0\n",
    "    while i < len(synt_info):\n",
    "        tok = synt_info[i]\n",
    "        if (tok[3] == 'VERB'):\n",
    "            forms = new_frame[new_frame['KeyLexemes'].str.contains(tok[2])]['Form'].tolist()\n",
    "            cases = list(set([x for x in list(chain.from_iterable(forms)) if x in obliq and x != 'Snom']))\n",
    "            roles = new_frame[new_frame['KeyLexemes'].str.contains(tok[2])]['Rank'].tolist()\n",
    "            fr = forms_and_roles(forms, roles)\n",
    "            fr = [x for x in fr if any(y in x[0] for y in obliq)]\n",
    "            if len(fr) > 0:\n",
    "                try:\n",
    "                    for j in hd[str(i+1)]:\n",
    "                        if (synt_info[int(j)-1][3] == 'NOUN') and (\n",
    "                            (synt_info[int(j)-1][7] == 'obj') or (synt_info[int(j)-1][7] == 'obl')) and (\n",
    "                        (j not in hd) or (all((synt_info[int(ind)-1][3] != 'ADP') for ind in hd[j]))):\n",
    "#                             print('Noun ind: ' + j)\n",
    "#                             print('Noun: {}'.format(synt_info[int(j)-1][2]))\n",
    "#                             print('Noun grams: {}'.format(synt_info[int(j)-1][5]))\n",
    "#                             print('Noun role: {}'.format(synt_info[int(j)-1][7]))\n",
    "                            frame_fs = list(set([grams[case][1] for case in cases]))\n",
    "#                             print(frame_fs)\n",
    "                            noun_fs = synt_info[int(j)-1][5].split('|')\n",
    "                            common = [x for x in noun_fs if x in frame_fs]\n",
    "                            if not common:\n",
    "                                lexem = morph.parse(synt_info[int(j)-1][2])\n",
    "                                try:\n",
    "                                    lex = [x for x in lexem if 'NOUN' in x.tag and 'nomn' in x.tag][0]\n",
    "                                except IndexError:\n",
    "                                    print('IndexError')\n",
    "                                    print(orig_sent)\n",
    "                                    continue\n",
    "                                hyp = {l.word for l in lex.lexeme if l.tag.POS == lex.tag.POS}\n",
    "                                orig_prob = sentence_prob(orig_sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model,\n",
    "                                                  batch_size=16)\n",
    "                                new_probs = dict()\n",
    "                                for h in hyp:\n",
    "                                    if synt_info[int(j)-1][1][0].isupper():\n",
    "                                        h = h.capitalize()\n",
    "                                    tmp = orig_sent.split()\n",
    "                                    tmp[int(j)-1] = h\n",
    "                                    new_sent = ' '.join(tmp)\n",
    "                                    new_prob = sentence_prob(new_sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model)\n",
    "                                    new_probs[str(new_prob)] = new_sent\n",
    "                                thr = 10\n",
    "                                new_dict = {k:v for (k,v) in new_probs.items() if float(k) > (orig_prob + thr)}\n",
    "                                if not new_dict:\n",
    "                                    continue\n",
    "                                max_item = max(new_dict.items(), key=lambda x: float(x[0]))\n",
    "                                orig_sent = max_item[1]\n",
    "#                                 orig_prob = float(max_item[0])\n",
    "                                print(orig_sent)\n",
    "                except KeyError:\n",
    "                    print('Нет такого индекса в словаре')\n",
    "        i += 1\n",
    "    with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/RULEC-GEC_test_ya_speller_punct_comma-masked-no-lowercase_prep-masked_prep-noun-masked_prep-noun-agr_frame-v+noun.txt', 'a', encoding='utf8') as f:\n",
    "        print(orig_sent, file=f, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Перебор словоформ прилагательных, зависимых от существительных, рубертом (skills_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/RULEC-GEC_test_ya_speller_punct_comma-masked-no-lowercase_prep-masked_prep-noun-masked_prep-noun-agr_frame-v+noun_parsed.txt',\n",
    "#          'r') as f:\n",
    "with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/excluded_test_ya_speller_punct_prep-masked_prep-noun-masked_frame-v+noun_parsed.txt',\n",
    "         'r') as f:\n",
    "    test_ya_parsed = f.read()\n",
    "sents = test_ya_parsed.split('\\n\\n')\n",
    "del sents[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54286386ab0341b9b056503f9e3c19f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#excluded\n",
    "for sent in tqdm(sents):\n",
    "    spl = sent.split('\\n')\n",
    "    synt_info = [x.split('\\t') for x in spl]\n",
    "    orig_sent = ' '.join(x[1] for x in synt_info)\n",
    "    i = 0\n",
    "    while i < len(synt_info):\n",
    "        tok = synt_info[i]\n",
    "        if (tok[3] == 'ADJ') and (tok[7] == 'amod' or tok[7] == 'root') and (synt_info[int(tok[6])-1][3] == 'NOUN' or (\n",
    "            tok[6] == '0')):\n",
    "            lexem = morph.parse(tok[2])\n",
    "            try:\n",
    "                lex = [x for x in lexem if 'ADJF' in x.tag][0]\n",
    "            except IndexError:\n",
    "                print('IndexError')\n",
    "                print(orig_sent)\n",
    "                i += 1\n",
    "                continue\n",
    "            hyp = {l.word for l in lex.lexeme if l.tag.POS == lex.tag.POS}\n",
    "            orig_prob = sentence_prob(orig_sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model,\n",
    "                                                  batch_size=16)\n",
    "            new_probs = dict()\n",
    "            for h in hyp:\n",
    "                if tok[1][0].isupper():\n",
    "                    h = h.capitalize()\n",
    "                tmp = orig_sent.split()\n",
    "                tmp[int(tok[0])-1] = h\n",
    "                new_sent = ' '.join(tmp)\n",
    "                new_prob = sentence_prob(new_sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model)\n",
    "                new_probs[str(new_prob)] = new_sent\n",
    "            thr = 10\n",
    "            new_dict = {k:v for (k,v) in new_probs.items() if float(k) > (orig_prob + thr)}\n",
    "            if not new_dict:\n",
    "                i += 1\n",
    "                continue\n",
    "            max_item = max(new_dict.items(), key=lambda x: float(x[0]))\n",
    "            orig_sent = max_item[1]\n",
    "            print(orig_sent)\n",
    "        i += 1\n",
    "    with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/excluded_test_ya_speller_punct_prep-masked_prep-noun-masked_frame-v+noun_adj-masked.txt', 'a', encoding='utf8') as f:\n",
    "        print(orig_sent, file=f, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b987a16cc74707b59d897805e885b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4637.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexError\n",
      "В 1926-ом году знаменитая американская артистка цирка Мэрион Диксон приезжает на гастроли в Москву .\n",
      "IndexError\n",
      "Конечно , много эмигрантов покидает свою родину в развивающемся « Втором мире » или неразвитом « Третьем мире » в поисках лучших экономических условий , большей степени религиозной свободы или большей степени политической свободы в развитых странах « Первого мира » .\n",
      "IndexError\n",
      "Конечно , много эмигрантов покидает свою родину в развивающемся « Втором мире » или неразвитом « Третьем мире » в поисках лучших экономических условий , большей степени религиозной свободы или большей степени политической свободы в развитых странах « Первого мира » .\n",
      "IndexError\n",
      "В России , также как и в США , в течение двадцатых годов не думали , что скоро будет Великая депрессия .\n",
      "IndexError\n",
      "Я родился в семье - пятым ребенком из двенадцати детей .\n",
      "IndexError\n",
      "За вторыми – будущее .\n",
      "IndexError\n",
      "На первой фотографии стоит молодая женщина , которая одета в стиле 70-х годов .\n",
      "IndexError\n",
      "Я знаю , что следующие национальные меньшинства проживали в США в 1920х гг . : азиаты ( особенно китайцы ) , немцы , ирландцы , поляки , евреи .\n"
     ]
    }
   ],
   "source": [
    "for sent in tqdm(sents[356:]):\n",
    "    spl = sent.split('\\n')\n",
    "    synt_info = [x.split('\\t') for x in spl]\n",
    "    orig_sent = ' '.join(x[1] for x in synt_info)\n",
    "    i = 0\n",
    "    while i < len(synt_info):\n",
    "        tok = synt_info[i]\n",
    "        if (tok[3] == 'ADJ') and (tok[7] == 'amod' or tok[7] == 'root') and (synt_info[int(tok[6])-1][3] == 'NOUN' or (\n",
    "            tok[6] == '0')):\n",
    "            lexem = morph.parse(tok[2])\n",
    "            try:\n",
    "                lex = [x for x in lexem if 'ADJF' in x.tag][0]\n",
    "            except IndexError:\n",
    "                print('IndexError')\n",
    "                print(orig_sent)\n",
    "                i += 1\n",
    "                continue\n",
    "            hyp = {l.word for l in lex.lexeme if l.tag.POS == lex.tag.POS}\n",
    "            orig_prob = sentence_prob(orig_sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model,\n",
    "                                                  batch_size=16)\n",
    "            new_probs = dict()\n",
    "            for h in hyp:\n",
    "                if tok[1][0].isupper():\n",
    "                    h = h.capitalize()\n",
    "                tmp = orig_sent.split()\n",
    "                tmp[int(tok[0])-1] = h\n",
    "                new_sent = ' '.join(tmp)\n",
    "                new_prob = sentence_prob(new_sent, bert_tokenizer=bert_tokenizer, bert_model=bert_model)\n",
    "                new_probs[str(new_prob)] = new_sent\n",
    "            thr = 10\n",
    "            new_dict = {k:v for (k,v) in new_probs.items() if float(k) > (orig_prob + thr)}\n",
    "            if not new_dict:\n",
    "                i += 1\n",
    "                continue\n",
    "            max_item = max(new_dict.items(), key=lambda x: float(x[0]))\n",
    "            orig_sent = max_item[1]\n",
    "            print(orig_sent)\n",
    "        i += 1\n",
    "    with open('/home/kravtsova/hse/thesis/RozovskayaRothTACL2018-dataset/skills_2/RULEC-GEC_test_ya_speller_punct_comma-masked-no-lowercase_prep-masked_prep-noun-masked_prep-noun-agr_frame-v+noun_adj-masked.txt', 'a', encoding='utf8') as f:\n",
    "        print(orig_sent, file=f, flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
